{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEMUILxS002Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load a sample dataset (replace this with your own dataset)\n",
        "ECG Data = (\"Path for the Dataset\")\n",
        "# Spliting target variable and independent variables\n",
        "X = data.drop([187],axis=1)\n",
        "y = data[187]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a list of classifiers\n",
        "classifiers = {\n",
        "    'SVM': SVC(),\n",
        "    'LogisticRegression': LogisticRegression()\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'knn':KNeighborsClassifier(n_neighbors=k),\n",
        "    'NB':GaussianNB(),\n",
        "    'XGb':XGBClassifier(objective='multi:softmax', num_class=5, random_state=42),\n",
        "    'LGBM':LGBMClassifier(objective='multiclass', num_class=5, random_state=42),\n",
        "    'BAG':BaggingClassifier(base_classifier, n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Define hyperparameters for each classifier\n",
        "param_grids = {\n",
        "    'RandomForest': {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]},\n",
        "    'SVM': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
        "    'LogisticRegression': {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "}\n",
        "\n",
        "# Iterate over classifiers\n",
        "for clf_name, clf in classifiers.items():\n",
        "    # Create a GridSearchCV object for the current classifier\n",
        "    grid_search = GridSearchCV(clf, param_grids[clf_name], cv=5, scoring='accuracy')\n",
        "\n",
        "    # Fit the GridSearchCV object to the data\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Train a new model with the best hyperparameters\n",
        "    best_clf = clf.set_params(**best_params)\n",
        "    best_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = best_clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_predbag)\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "    print(f\"Accuracy on Test Set: {accuracy}\")\n",
        "    print(\"-----------------------------\")\n"
      ]
    }
  ]
}